{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maruddo/AI-Notebooks/blob/main/heart_disease_model/heart_disease.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "641382ab-b734-4edb-849b-e6510c0a7e92",
      "metadata": {
        "id": "641382ab-b734-4edb-849b-e6510c0a7e92"
      },
      "source": [
        "# HEART DISEASE MODEL - PYTORCH"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d353825a-82b7-4543-8bea-3f5592361c85",
      "metadata": {
        "id": "d353825a-82b7-4543-8bea-3f5592361c85"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a124df7-9f52-48b7-b0ca-a060b7d14812",
      "metadata": {
        "id": "5a124df7-9f52-48b7-b0ca-a060b7d14812"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader, random_split\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3112835b-3d7b-4005-a64c-844c35d87d08",
      "metadata": {
        "id": "3112835b-3d7b-4005-a64c-844c35d87d08"
      },
      "source": [
        "# Create Dataset from file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6529da24-d108-4d05-baef-42930bd4d7ba",
      "metadata": {
        "id": "6529da24-d108-4d05-baef-42930bd4d7ba"
      },
      "outputs": [],
      "source": [
        "def import_dataset(dataset):\n",
        "    dataset = np.genfromtxt(dataset,\n",
        "                            delimiter = ',',\n",
        "                            dtype=[('data', \"float32\", (13,)), ('target', \"int64\")],\n",
        "                            usemask=True,\n",
        "                            skip_header=1)\n",
        "    data = dataset['data']\n",
        "    target = dataset['target']\n",
        "    original_labels = [\n",
        "    \"AGE\", \"SEX\", \"CP\", \"TRESTBPS\", \"CHOL\", \"FBS\", \"RESTECG\", \"THALACH\", \"EXANG\", \"OLDPEAK\",  \"SLOPE\", \"CA\", \"THAL\"\n",
        "    ]\n",
        "\n",
        "    new_labels = (\n",
        "        original_labels[2:] +  [\"WOMEN\", \"MAN\"] + [\"0-30\", \"30-50\", \"50-70\", \"70-100\"]\n",
        "    )\n",
        "\n",
        "    new_X = split_columns(data)\n",
        "\n",
        "    new_X = (new_X - np.min(new_X, axis=0, keepdims=True)) / np.max(new_X, axis=0, keepdims=True)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "\n",
        "    features_tensor = torch.from_numpy(np.array(new_X))\n",
        "\n",
        "    labels_tensor = torch.from_numpy(np.array(target))\n",
        "\n",
        "    # Create a TensorDataset\n",
        "    full_dataset = TensorDataset(features_tensor, labels_tensor)\n",
        "    return full_dataset\n",
        "\n",
        "def split_columns(data):\n",
        "    bins = [0, 30, 50, 70, 100] #Límites de los rangos de edad hasta 100\n",
        "    bins.sort() # Asegurarse de que los bins estén en orden creciente\n",
        "    edad_rangos = np.digitize(data[:, 0], bins) - 1  # -1 para que los índices empiecen desde 0\n",
        "\n",
        "    sexo_one_hot = np.eye(2, dtype=np.float32)[data[:, 1].astype(int)] #Crea las columnas [mujer, hombre]\n",
        "    edad_one_hot = np.eye(len(bins) - 1, dtype=np.float32)[edad_rangos] #Crea columnas binarias para cada rango de edad\n",
        "\n",
        "    data_without_sex_age = np.delete(data, [0, 1], axis=1) #Eliminar las columnas originales de edad y sexo\n",
        "\n",
        "    new_X = np.hstack((data_without_sex_age, sexo_one_hot, edad_one_hot)) #Concatenar el dataset con las columnas codificadas\n",
        "    return new_X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5473998e-8e86-457b-af2b-fdaf7003ea6d",
      "metadata": {
        "id": "5473998e-8e86-457b-af2b-fdaf7003ea6d"
      },
      "source": [
        "## Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eee46a3-5711-41a4-abdf-8c179cb17806",
      "metadata": {
        "id": "6eee46a3-5711-41a4-abdf-8c179cb17806"
      },
      "outputs": [],
      "source": [
        "def split_dataset(full_dataset):\n",
        "    train_size = int(0.8 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "    training_data, test_data = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "    return training_data, test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f58011a-5ba0-46db-8b33-d3b10b809aa6",
      "metadata": {
        "id": "4f58011a-5ba0-46db-8b33-d3b10b809aa6"
      },
      "source": [
        "# Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0eaaf12-46c1-4d66-aa33-37bf508e366b",
      "metadata": {
        "id": "a0eaaf12-46c1-4d66-aa33-37bf508e366b"
      },
      "outputs": [],
      "source": [
        "def create_dataloader(training_data, test_data,batch_size):\n",
        "    train_dataloader = DataLoader(training_data, batch_size, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_data, batch_size, shuffle=False)\n",
        "\n",
        "    return train_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fd55dee-4ea5-4247-8133-18efabba29fa",
      "metadata": {
        "id": "7fd55dee-4ea5-4247-8133-18efabba29fa"
      },
      "source": [
        "# Select Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a85a21-4612-42a1-b095-bba2b8bd5cc8",
      "metadata": {
        "id": "a5a85a21-4612-42a1-b095-bba2b8bd5cc8"
      },
      "outputs": [],
      "source": [
        "def select_device():\n",
        "    device = (\n",
        "        \"cuda\"\n",
        "        if torch.cuda.is_available()\n",
        "        else \"mps\"\n",
        "        if torch.backends.mps.is_available()\n",
        "        else \"cpu\"\n",
        "    )\n",
        "    return device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01780fa5-3e33-4d0c-bb6e-2bce7366b966",
      "metadata": {
        "id": "01780fa5-3e33-4d0c-bb6e-2bce7366b966"
      },
      "source": [
        "# Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dc31549-5a22-4790-98db-be911a024512",
      "metadata": {
        "id": "0dc31549-5a22-4790-98db-be911a024512"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(17, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 35),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(35, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "def load_model(weights, device):\n",
        "    model = NeuralNetwork().to(device)\n",
        "    if os.path.exists(weights):\n",
        "         try:\n",
        "             model.load_state_dict(torch.load(weights, mmap=True, weights_only=True), assign=True)\n",
        "         except:\n",
        "             print(\"None weights were loaded\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd5a86e2-b9a4-45d9-8133-90777b8a0d66",
      "metadata": {
        "id": "fd5a86e2-b9a4-45d9-8133-90777b8a0d66"
      },
      "source": [
        "# Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09107035-d401-4fbf-81bf-6a7ae6889d77",
      "metadata": {
        "id": "09107035-d401-4fbf-81bf-6a7ae6889d77"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn, device, best_accuracy, best_weights):\n",
        "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    accuracy = correct / size\n",
        "\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    if should_save_best_model(accuracy, best_accuracy):\n",
        "        best_accuracy = accuracy\n",
        "        best_weights = model.state_dict()\n",
        "\n",
        "    return best_accuracy, best_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save only the best weights (optional and not useful for all cases)"
      ],
      "metadata": {
        "id": "g2rSXchYmv56"
      },
      "id": "g2rSXchYmv56"
    },
    {
      "cell_type": "code",
      "source": [
        "def should_save_best_model(accuracy, best_accuracy):\n",
        "    return accuracy > best_accuracy"
      ],
      "metadata": {
        "id": "n-MdL8g8mwbS"
      },
      "id": "n-MdL8g8mwbS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d7b9dee4-2472-4618-93b6-7ede020c97c5",
      "metadata": {
        "id": "d7b9dee4-2472-4618-93b6-7ede020c97c5"
      },
      "source": [
        "# Personal data formulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00cce26f-1a2f-425f-be03-38ac99fed52a",
      "metadata": {
        "id": "00cce26f-1a2f-425f-be03-38ac99fed52a"
      },
      "outputs": [],
      "source": [
        "def enter_data(model, device):\n",
        "    age = int(input(\"Enter your age: \"))\n",
        "\n",
        "    sex = int(input(\"Enter your sex (0 for female, 1 for male):\"))\n",
        "\n",
        "    chest_pain_type = int(input(\"Enter the type of chest pain (0-3): \"))\n",
        "\n",
        "    resting_blood_pressure = int(input(\"Enter your resting blood pressure (in mm Hg):\"))\n",
        "\n",
        "    cholesterol = int(input(\"Enter your cholesterol level (in mg/dl): \"))\n",
        "\n",
        "    fasting_blood_sugar = int(input(\"Enter your fasting blood sugar level (1 if > 120 mg/dl, 0 if not): \"))\n",
        "\n",
        "    rest_ecg = int(input(\"Enter the resting electrocardiographic results (0-2): \"))\n",
        "\n",
        "    max_heart_rate = int(input(\"Enter your maximum heart rate achieved: \"))\n",
        "\n",
        "    exercise_induced_angina = int(input(\"Did you have exercise-induced angina? (1 for yes, 0 for no): \"))\n",
        "\n",
        "    oldpeak = float(input(\"Enter the ST depression value induced by exercise (oldpeak): \"))\n",
        "\n",
        "    st_slope = int(input(\"Enter the slope of the peak exercise ST segment (0-2): \"))\n",
        "\n",
        "    major_vessels = int(input(\"Enter the number of major vessels colored by fluoroscopy (0-3): \"))\n",
        "\n",
        "    thalassemia = int(input(\"Enter the type of thalassemia (1 = normal, 2 = fixed defect, 3 = reversible defect): \"))\n",
        "\n",
        "    input_data = [age, sex, chest_pain_type, resting_blood_pressure, cholesterol, fasting_blood_sugar, rest_ecg,\n",
        "                  max_heart_rate, exercise_induced_angina, oldpeak, st_slope, major_vessels, thalassemia]\n",
        "\n",
        "    input_data = personal_data_split(input_data)\n",
        "    input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        probabilities = torch.softmax(output, dim=1)\n",
        "        predicted_class = probabilities.argmax(1).item()\n",
        "\n",
        "    return predicted_class\n",
        "\n",
        "def personal_data_split(data):\n",
        "    rangos = [0, 30, 50, 70, 100]\n",
        "    edad_rangos = np.digitize([data[0]], rangos) - 1\n",
        "    sexo_one_hot = np.eye(2)[[data[1]]]\n",
        "    edad_one_hot = np.eye(len(rangos) - 1)[edad_rangos]\n",
        "\n",
        "    processed_data = np.hstack((data[2:], sexo_one_hot[0], edad_one_hot[0]))\n",
        "\n",
        "    return processed_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f3f0f9-5d9c-41f3-9ffb-3ba4258703c3",
      "metadata": {
        "id": "65f3f0f9-5d9c-41f3-9ffb-3ba4258703c3"
      },
      "source": [
        "# Main Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2809379-a2c6-4b6e-a017-5876a179b423",
      "metadata": {
        "id": "b2809379-a2c6-4b6e-a017-5876a179b423"
      },
      "outputs": [],
      "source": [
        "def main(dataset, learning_rate, batch_size, epochs):\n",
        "    device = select_device()\n",
        "    model = load_model('model_weights.pth', device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    best_accuracy = 0.0\n",
        "    best_weights = None\n",
        "\n",
        "    train_on = input(\"Do you want to train? Yes(Any), No(enter): \")\n",
        "    if train_on:\n",
        "        full_dataset = import_dataset(dataset)\n",
        "        training_data, test_data = split_dataset(full_dataset)\n",
        "        train_dataloader, test_dataloader = create_dataloader(training_data, test_data, batch_size)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        next_train = True\n",
        "        while next_train:\n",
        "            for t in range(epochs):\n",
        "                print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "                train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
        "                best_accuracy, best_weights = test_loop(test_dataloader, model, loss_fn, device, best_accuracy, best_weights)\n",
        "\n",
        "            print(f\"Best accuracy: {(100 * best_accuracy):.1f}% with learning rate {learning_rate}\")\n",
        "            save_on = input(\"Do you want to save? Yes(Any), No(enter): \")\n",
        "            if save_on:\n",
        "              print(\"Done! Saving process...\")\n",
        "              torch.save(best_weights, 'model_weights.pth')\n",
        "\n",
        "            stop_train = input(\"Should we continue training? No(Any) Yes(Enter) -> \")\n",
        "            if stop_train:\n",
        "                next_train = False\n",
        "            else:\n",
        "                change_lr = input(\"Change the learning rate? Yes(Any) No(Enter) -> \")\n",
        "                if change_lr:\n",
        "                    try:\n",
        "                        learning_rate = float(input(\"New learning rate: \"))\n",
        "                    except:\n",
        "                        print(\"Ignoring new learning rate\")\n",
        "\n",
        "                change_epochs = input(f\"Change the number of epochs ({epochs})? Yes(Any) No(Enter) -> \")\n",
        "                if change_epochs:\n",
        "                    try:\n",
        "                        epochs = int(input(\"New number of epochs: \"))\n",
        "                    except:\n",
        "                        print(\"Ignoring new number of epochs\")\n",
        "    else:\n",
        "        print(f\"Predicted class: {enter_data(model, device)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e542b086-96ed-4afe-9c67-18cff3c33205",
      "metadata": {
        "id": "e542b086-96ed-4afe-9c67-18cff3c33205"
      },
      "source": [
        "# Call main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe67d998-4d3f-4fa5-b29f-ecb98a03f4d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe67d998-4d3f-4fa5-b29f-ecb98a03f4d3",
        "outputId": "1853f6ec-f74f-466d-fdc8-14b365f1b8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do you want to train? Yes(Any), No(enter): y\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.695507  [   32/  820]\n",
            "loss: 0.659141  [  352/  820]\n",
            "loss: 0.625674  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 76.1%, Avg loss: 0.622451 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.634298  [   32/  820]\n",
            "loss: 0.566821  [  352/  820]\n",
            "loss: 0.518504  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 76.1%, Avg loss: 0.534774 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.526729  [   32/  820]\n",
            "loss: 0.413830  [  352/  820]\n",
            "loss: 0.370369  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 78.5%, Avg loss: 0.437223 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.436423  [   32/  820]\n",
            "loss: 0.356687  [  352/  820]\n",
            "loss: 0.463974  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.382232 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.267434  [   32/  820]\n",
            "loss: 0.373432  [  352/  820]\n",
            "loss: 0.395196  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 0.375947 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.294261  [   32/  820]\n",
            "loss: 0.423532  [  352/  820]\n",
            "loss: 0.340191  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.361061 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.353092  [   32/  820]\n",
            "loss: 0.364933  [  352/  820]\n",
            "loss: 0.267877  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 0.358342 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.304317  [   32/  820]\n",
            "loss: 0.322576  [  352/  820]\n",
            "loss: 0.327707  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.344754 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.234870  [   32/  820]\n",
            "loss: 0.423787  [  352/  820]\n",
            "loss: 0.373055  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 0.351793 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.438339  [   32/  820]\n",
            "loss: 0.266350  [  352/  820]\n",
            "loss: 0.279077  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 85.4%, Avg loss: 0.348822 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.302639  [   32/  820]\n",
            "loss: 0.192131  [  352/  820]\n",
            "loss: 0.254231  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.335877 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.387452  [   32/  820]\n",
            "loss: 0.316653  [  352/  820]\n",
            "loss: 0.236243  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.320340 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.319100  [   32/  820]\n",
            "loss: 0.369554  [  352/  820]\n",
            "loss: 0.217930  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.319223 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.291013  [   32/  820]\n",
            "loss: 0.334827  [  352/  820]\n",
            "loss: 0.449318  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.337729 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.218184  [   32/  820]\n",
            "loss: 0.294403  [  352/  820]\n",
            "loss: 0.323021  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.323879 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.250490  [   32/  820]\n",
            "loss: 0.242091  [  352/  820]\n",
            "loss: 0.090514  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.301077 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.253808  [   32/  820]\n",
            "loss: 0.217973  [  352/  820]\n",
            "loss: 0.248501  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.299835 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.155042  [   32/  820]\n",
            "loss: 0.252668  [  352/  820]\n",
            "loss: 0.254016  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.2%, Avg loss: 0.304479 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.217072  [   32/  820]\n",
            "loss: 0.157799  [  352/  820]\n",
            "loss: 0.197014  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.292103 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.432977  [   32/  820]\n",
            "loss: 0.122720  [  352/  820]\n",
            "loss: 0.254673  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.300944 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.274104  [   32/  820]\n",
            "loss: 0.233497  [  352/  820]\n",
            "loss: 0.241609  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.286314 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.237712  [   32/  820]\n",
            "loss: 0.107609  [  352/  820]\n",
            "loss: 0.275241  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 0.286092 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.232104  [   32/  820]\n",
            "loss: 0.228205  [  352/  820]\n",
            "loss: 0.289817  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.277963 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.092716  [   32/  820]\n",
            "loss: 0.197515  [  352/  820]\n",
            "loss: 0.220245  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.284062 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.111600  [   32/  820]\n",
            "loss: 0.104580  [  352/  820]\n",
            "loss: 0.247564  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.277440 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.254775  [   32/  820]\n",
            "loss: 0.104194  [  352/  820]\n",
            "loss: 0.118672  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.276571 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.134514  [   32/  820]\n",
            "loss: 0.163309  [  352/  820]\n",
            "loss: 0.212777  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.262510 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.231579  [   32/  820]\n",
            "loss: 0.112471  [  352/  820]\n",
            "loss: 0.216847  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.2%, Avg loss: 0.279230 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.117139  [   32/  820]\n",
            "loss: 0.108943  [  352/  820]\n",
            "loss: 0.212763  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.260264 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.169933  [   32/  820]\n",
            "loss: 0.180944  [  352/  820]\n",
            "loss: 0.251241  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.269879 \n",
            "\n",
            "Best accuracy: 92.2% with learning rate 0.001\n",
            "Do you want to save? Yes(Any), No(enter): y\n",
            "Done! Saving process...\n",
            "Should we continue training? No(Any) Yes(Enter) -> n\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    dataset = 'dataset/heart.csv'\n",
        "    learning_rate = 1e-3\n",
        "    batch_size = 32\n",
        "    epochs = 30\n",
        "    main(dataset,learning_rate,batch_size,epochs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PYTORCH",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}