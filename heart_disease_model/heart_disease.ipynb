{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maruddo/AI-Notebooks/blob/main/heart_disease_model/heart_disease.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "641382ab-b734-4edb-849b-e6510c0a7e92",
      "metadata": {
        "id": "641382ab-b734-4edb-849b-e6510c0a7e92"
      },
      "source": [
        "# HEART DISEASE MODEL - PYTORCH"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d353825a-82b7-4543-8bea-3f5592361c85",
      "metadata": {
        "id": "d353825a-82b7-4543-8bea-3f5592361c85"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a124df7-9f52-48b7-b0ca-a060b7d14812",
      "metadata": {
        "id": "5a124df7-9f52-48b7-b0ca-a060b7d14812"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader, random_split\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3112835b-3d7b-4005-a64c-844c35d87d08",
      "metadata": {
        "id": "3112835b-3d7b-4005-a64c-844c35d87d08"
      },
      "source": [
        "# Create Dataset from file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6529da24-d108-4d05-baef-42930bd4d7ba",
      "metadata": {
        "id": "6529da24-d108-4d05-baef-42930bd4d7ba"
      },
      "outputs": [],
      "source": [
        "def import_dataset(dataset):\n",
        "    dataset = np.genfromtxt(dataset,\n",
        "                            delimiter = ',',\n",
        "                            dtype=[('data', \"float32\", (13,)), ('target', \"int64\")],\n",
        "                            usemask=True,\n",
        "                            skip_header=1)\n",
        "    data = dataset['data']\n",
        "    target = dataset['target']\n",
        "    original_labels = [\n",
        "    \"AGE\", \"SEX\", \"CP\", \"TRESTBPS\", \"CHOL\", \"FBS\", \"RESTECG\", \"THALACH\", \"EXANG\", \"OLDPEAK\",  \"SLOPE\", \"CA\", \"THAL\"\n",
        "    ]\n",
        "\n",
        "    new_labels = (\n",
        "        original_labels[2:] +  [\"WOMEN\", \"MAN\"] + [\"0-30\", \"30-50\", \"50-70\", \"70-100\"]\n",
        "    )\n",
        "\n",
        "    new_X = split_columns(data)\n",
        "\n",
        "    new_X = (new_X - np.min(new_X, axis=0, keepdims=True)) / np.max(new_X, axis=0, keepdims=True)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "\n",
        "    features_tensor = torch.from_numpy(np.array(new_X))\n",
        "\n",
        "\n",
        "    labels_tensor = torch.from_numpy(np.array(target))\n",
        "\n",
        "\n",
        "    # Create a TensorDataset\n",
        "    full_dataset = TensorDataset(features_tensor, labels_tensor)\n",
        "    return full_dataset\n",
        "\n",
        "def split_columns(data):\n",
        "    bins = [0, 30, 50, 70, 100] #Límites de los rangos de edad hasta 100\n",
        "    bins.sort() # Asegurarse de que los bins estén en orden creciente\n",
        "    edad_rangos = np.digitize(data[:, 0], bins) - 1  # -1 para que los índices empiecen desde 0\n",
        "\n",
        "    sexo_one_hot = np.eye(2, dtype=np.float32)[data[:, 1].astype(int)] #Crea las columnas [mujer, hombre]\n",
        "    edad_one_hot = np.eye(len(bins) - 1, dtype=np.float32)[edad_rangos] #Crea columnas binarias para cada rango de edad\n",
        "\n",
        "    data_without_sex_age = np.delete(data, [0, 1], axis=1) #Eliminar las columnas originales de edad y sexo\n",
        "\n",
        "    new_X = np.hstack((data_without_sex_age, sexo_one_hot, edad_one_hot)) #Concatenar el dataset con las columnas codificadas\n",
        "    return new_X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5473998e-8e86-457b-af2b-fdaf7003ea6d",
      "metadata": {
        "id": "5473998e-8e86-457b-af2b-fdaf7003ea6d"
      },
      "source": [
        "## Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eee46a3-5711-41a4-abdf-8c179cb17806",
      "metadata": {
        "id": "6eee46a3-5711-41a4-abdf-8c179cb17806"
      },
      "outputs": [],
      "source": [
        "def split_dataset(full_dataset):\n",
        "    train_size = int(0.8 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "    training_data, test_data = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "    return training_data, test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f58011a-5ba0-46db-8b33-d3b10b809aa6",
      "metadata": {
        "id": "4f58011a-5ba0-46db-8b33-d3b10b809aa6"
      },
      "source": [
        "# Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0eaaf12-46c1-4d66-aa33-37bf508e366b",
      "metadata": {
        "id": "a0eaaf12-46c1-4d66-aa33-37bf508e366b"
      },
      "outputs": [],
      "source": [
        "def create_dataloader(training_data, test_data,batch_size):\n",
        "    train_dataloader = DataLoader(training_data, batch_size, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_data, batch_size, shuffle=False)\n",
        "\n",
        "    return train_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fd55dee-4ea5-4247-8133-18efabba29fa",
      "metadata": {
        "id": "7fd55dee-4ea5-4247-8133-18efabba29fa"
      },
      "source": [
        "# Select Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a85a21-4612-42a1-b095-bba2b8bd5cc8",
      "metadata": {
        "id": "a5a85a21-4612-42a1-b095-bba2b8bd5cc8"
      },
      "outputs": [],
      "source": [
        "def select_device():\n",
        "    device = (\n",
        "        \"cuda\"\n",
        "        if torch.cuda.is_available()\n",
        "        else \"mps\"\n",
        "        if torch.backends.mps.is_available()\n",
        "        else \"cpu\"\n",
        "    )\n",
        "    return device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01780fa5-3e33-4d0c-bb6e-2bce7366b966",
      "metadata": {
        "id": "01780fa5-3e33-4d0c-bb6e-2bce7366b966"
      },
      "source": [
        "# Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dc31549-5a22-4790-98db-be911a024512",
      "metadata": {
        "id": "0dc31549-5a22-4790-98db-be911a024512"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(17, 100),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(100, 35),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(35, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "def load_model(weights, device):\n",
        "    model = NeuralNetwork().to(device)\n",
        "    if os.path.exists(weights):\n",
        "         try:\n",
        "             model.load_state_dict(torch.load(weights, mmap=True, weights_only=True), assign=True)\n",
        "         except:\n",
        "             print(\"None weights were loaded\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd5a86e2-b9a4-45d9-8133-90777b8a0d66",
      "metadata": {
        "id": "fd5a86e2-b9a4-45d9-8133-90777b8a0d66"
      },
      "source": [
        "# Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09107035-d401-4fbf-81bf-6a7ae6889d77",
      "metadata": {
        "id": "09107035-d401-4fbf-81bf-6a7ae6889d77"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 25 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn, device):\n",
        "    global best_weights, best_correct\n",
        "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    if best_correct < correct:\n",
        "        best_correct = correct\n",
        "        best_weights = model.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7b9dee4-2472-4618-93b6-7ede020c97c5",
      "metadata": {
        "id": "d7b9dee4-2472-4618-93b6-7ede020c97c5"
      },
      "source": [
        "# Personal data formulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00cce26f-1a2f-425f-be03-38ac99fed52a",
      "metadata": {
        "id": "00cce26f-1a2f-425f-be03-38ac99fed52a"
      },
      "outputs": [],
      "source": [
        "def enter_data(model, device):\n",
        "    age = int(input(\"Enter your age: \"))\n",
        "\n",
        "    sex = int(input(\"Enter your sex (0 for female, 1 for male):\"))\n",
        "\n",
        "    chest_pain_type = int(input(\"Enter the type of chest pain (0-3): \"))\n",
        "\n",
        "    resting_blood_pressure = int(input(\"Enter your resting blood pressure (in mm Hg):\"))\n",
        "\n",
        "    cholesterol = int(input(\"Enter your cholesterol level (in mg/dl): \"))\n",
        "\n",
        "    fasting_blood_sugar = int(input(\"Enter your fasting blood sugar level (1 if > 120 mg/dl, 0 if not): \"))\n",
        "\n",
        "    rest_ecg = int(input(\"Enter the resting electrocardiographic results (0-2): \"))\n",
        "\n",
        "    max_heart_rate = int(input(\"Enter your maximum heart rate achieved: \"))\n",
        "\n",
        "    exercise_induced_angina = int(input(\"Did you have exercise-induced angina? (1 for yes, 0 for no): \"))\n",
        "\n",
        "    oldpeak = float(input(\"Enter the ST depression value induced by exercise (oldpeak): \"))\n",
        "\n",
        "    st_slope = int(input(\"Enter the slope of the peak exercise ST segment (0-2): \"))\n",
        "\n",
        "    major_vessels = int(input(\"Enter the number of major vessels colored by fluoroscopy (0-3): \"))\n",
        "\n",
        "    thalassemia = int(input(\"Enter the type of thalassemia (1 = normal, 2 = fixed defect, 3 = reversible defect): \"))\n",
        "\n",
        "    input_data = [age, sex, chest_pain_type, resting_blood_pressure, cholesterol, fasting_blood_sugar, rest_ecg,\n",
        "                  max_heart_rate, exercise_induced_angina, oldpeak, st_slope, major_vessels, thalassemia]\n",
        "\n",
        "    input_data = personal_data_split(input_data)\n",
        "    input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        probabilities = torch.softmax(output, dim=1)\n",
        "        predicted_class = probabilities.argmax(1).item()\n",
        "\n",
        "    return predicted_class\n",
        "\n",
        "def personal_data_split(data):\n",
        "    rangos = [0, 30, 50, 70, 100]\n",
        "    edad_rangos = np.digitize([data[0]], rangos) - 1\n",
        "    sexo_one_hot = np.eye(2)[[data[1]]]\n",
        "    edad_one_hot = np.eye(len(rangos) - 1)[edad_rangos]\n",
        "\n",
        "    processed_data = np.hstack((data[2:], sexo_one_hot[0], edad_one_hot[0]))\n",
        "\n",
        "    return processed_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f3f0f9-5d9c-41f3-9ffb-3ba4258703c3",
      "metadata": {
        "id": "65f3f0f9-5d9c-41f3-9ffb-3ba4258703c3"
      },
      "source": [
        "# Main Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2809379-a2c6-4b6e-a017-5876a179b423",
      "metadata": {
        "id": "b2809379-a2c6-4b6e-a017-5876a179b423"
      },
      "outputs": [],
      "source": [
        "def __main__(dataset,learning_rate,batch_size,epochs):\n",
        "    device = select_device()\n",
        "    model = load_model('model_weights.pth', device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    train_on = input(\"Do you want to train? Yes(y), No(enter)\")\n",
        "    if train_on:\n",
        "        full_dataset = import_dataset(dataset)\n",
        "        training_data, test_data = split_dataset(full_dataset)\n",
        "        train_dataloader, test_dataloader = create_dataloader(training_data,test_data,batch_size)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        next_train = True\n",
        "        while next_train:\n",
        "            for t in range(epochs):\n",
        "                print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "                train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
        "                test_loop(test_dataloader, model, loss_fn, device)\n",
        "            print(\"Done! Saving process...\")\n",
        "            torch.save(best_weights, 'model_weights.pth')\n",
        "            print(f\"Best Accuracy: {(100*best_correct):>0.1f}% Using Learning Rate: {learning_rate}\")\n",
        "            stop_train = input(\"Should we continue training? No(Any) Yes(Enter) -> \")\n",
        "            if stop_train:\n",
        "                next_train = False\n",
        "            else:\n",
        "                change_lr = input(\"Change the learning rate? Yes(Any) No(Enter) -> \")\n",
        "                if change_lr:\n",
        "                    try:\n",
        "                        learning_rate=float(input(\"New learning rate: \"))\n",
        "                    except:\n",
        "                        print(\"Ignoring new learning rate\")\n",
        "                change_epochs = input(f\"Change the number of epochs ({epochs})? Yes(Any) No(Enter) -> \")\n",
        "                if change_epochs:\n",
        "                    try:\n",
        "                        epochs=int(input(\"New number of epochs: \"))\n",
        "                    except:\n",
        "                        print(\"Ignoring new learning rate\")\n",
        "    else:\n",
        "        print(f\"Predicted class: {enter_data(model, device)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e542b086-96ed-4afe-9c67-18cff3c33205",
      "metadata": {
        "id": "e542b086-96ed-4afe-9c67-18cff3c33205"
      },
      "source": [
        "# Call main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe67d998-4d3f-4fa5-b29f-ecb98a03f4d3",
      "metadata": {
        "id": "fe67d998-4d3f-4fa5-b29f-ecb98a03f4d3",
        "outputId": "1955f8ba-c4a9-447d-ee19-dea742897361"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Do you want to train? Yes(y), No(enter) y\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.353779  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.258390 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.360204  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.259477 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.350064  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.260721 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.350342  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.260900 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.347602  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.261014 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.347604  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.261054 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.341300  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.261000 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.340317  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.260801 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.349097  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.260775 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.342535  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.260880 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.338594  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.260213 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.331959  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.259031 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.340237  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.258160 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.337215  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.257552 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.335742  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.257109 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.335396  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.256752 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.335356  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.256668 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.332581  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.2%, Avg loss: 0.256522 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.328400  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.2%, Avg loss: 0.255934 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.328246  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.255061 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.329461  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.254309 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.324472  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.253628 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.331934  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.2%, Avg loss: 0.253049 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.323250  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 0.252579 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.322561  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 0.252149 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.317094  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 0.251472 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.323138  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 0.250677 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.319043  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 0.249758 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.314470  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.2%, Avg loss: 0.248971 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.317935  [  820/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.2%, Avg loss: 0.248439 \n",
            "\n",
            "Done! Saving process...\n",
            "Best Accuracy: 90.7% Using Learning Rate: 0.001\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    best_correct = 0\n",
        "    best_weights = None\n",
        "    dataset = 'dataset/heart.csv'\n",
        "    learning_rate = 1e-3\n",
        "    batch_size = 1025\n",
        "    epochs = 30\n",
        "    __main__(dataset,learning_rate,batch_size,epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66fd2d27-d121-407a-89b8-96bd6ce70a3e",
      "metadata": {
        "id": "66fd2d27-d121-407a-89b8-96bd6ce70a3e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PYTORCH",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}