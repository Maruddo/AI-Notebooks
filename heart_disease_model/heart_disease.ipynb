{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "641382ab-b734-4edb-849b-e6510c0a7e92",
      "metadata": {
        "id": "641382ab-b734-4edb-849b-e6510c0a7e92"
      },
      "source": [
        "# HEART DISEASE MODEL - PYTORCH"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d353825a-82b7-4543-8bea-3f5592361c85",
      "metadata": {
        "id": "d353825a-82b7-4543-8bea-3f5592361c85"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5a124df7-9f52-48b7-b0ca-a060b7d14812",
      "metadata": {
        "id": "5a124df7-9f52-48b7-b0ca-a060b7d14812"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader, random_split\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3112835b-3d7b-4005-a64c-844c35d87d08",
      "metadata": {
        "id": "3112835b-3d7b-4005-a64c-844c35d87d08"
      },
      "source": [
        "# Create Dataset from file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6529da24-d108-4d05-baef-42930bd4d7ba",
      "metadata": {
        "id": "6529da24-d108-4d05-baef-42930bd4d7ba"
      },
      "outputs": [],
      "source": [
        "def import_dataset(dataset):\n",
        "    dataset = np.genfromtxt(dataset,\n",
        "                            delimiter = ',',\n",
        "                            dtype=[('data', \"float32\", (13,)), ('target', \"int64\")],\n",
        "                            usemask=True,\n",
        "                            skip_header=1)\n",
        "    data = dataset['data']\n",
        "    target = dataset['target']\n",
        "    original_labels = [\n",
        "    \"AGE\", \"SEX\", \"CP\", \"TRESTBPS\", \"CHOL\", \"FBS\", \"RESTECG\", \"THALACH\", \"EXANG\", \"OLDPEAK\",  \"SLOPE\", \"CA\", \"THAL\"\n",
        "    ]\n",
        "\n",
        "    new_labels = (\n",
        "        original_labels[2:] +  [\"WOMEN\", \"MAN\"] + [\"0-30\", \"30-50\", \"50-70\", \"70-100\"]\n",
        "    )\n",
        "\n",
        "    new_X = split_columns(data)\n",
        "\n",
        "    new_X = (new_X - np.min(new_X, axis=0, keepdims=True)) / np.max(new_X, axis=0, keepdims=True)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "\n",
        "    features_tensor = torch.from_numpy(np.array(new_X))\n",
        "\n",
        "    labels_tensor = torch.from_numpy(np.array(target))\n",
        "\n",
        "    # Create a TensorDataset\n",
        "    full_dataset = TensorDataset(features_tensor, labels_tensor)\n",
        "    return full_dataset\n",
        "\n",
        "def split_columns(data):\n",
        "    bins = [0, 30, 50, 70, 100] #Límites de los rangos de edad hasta 100\n",
        "    bins.sort() # Asegurarse de que los bins estén en orden creciente\n",
        "    edad_rangos = np.digitize(data[:, 0], bins) - 1  # -1 para que los índices empiecen desde 0\n",
        "\n",
        "    sexo_one_hot = np.eye(2, dtype=np.float32)[data[:, 1].astype(int)] #Crea las columnas [mujer, hombre]\n",
        "    edad_one_hot = np.eye(len(bins) - 1, dtype=np.float32)[edad_rangos] #Crea columnas binarias para cada rango de edad\n",
        "\n",
        "    data_without_sex_age = np.delete(data, [0, 1], axis=1) #Eliminar las columnas originales de edad y sexo\n",
        "\n",
        "    new_X = np.hstack((data_without_sex_age, sexo_one_hot, edad_one_hot)) #Concatenar el dataset con las columnas codificadas\n",
        "    return new_X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5473998e-8e86-457b-af2b-fdaf7003ea6d",
      "metadata": {
        "id": "5473998e-8e86-457b-af2b-fdaf7003ea6d"
      },
      "source": [
        "## Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6eee46a3-5711-41a4-abdf-8c179cb17806",
      "metadata": {
        "id": "6eee46a3-5711-41a4-abdf-8c179cb17806"
      },
      "outputs": [],
      "source": [
        "def split_dataset(full_dataset):\n",
        "    train_size = int(0.8 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "    training_data, test_data = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "    return training_data, test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f58011a-5ba0-46db-8b33-d3b10b809aa6",
      "metadata": {
        "id": "4f58011a-5ba0-46db-8b33-d3b10b809aa6"
      },
      "source": [
        "# Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a0eaaf12-46c1-4d66-aa33-37bf508e366b",
      "metadata": {
        "id": "a0eaaf12-46c1-4d66-aa33-37bf508e366b"
      },
      "outputs": [],
      "source": [
        "def create_dataloader(training_data, test_data,batch_size):\n",
        "    train_dataloader = DataLoader(training_data, batch_size, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_data, batch_size, shuffle=False)\n",
        "\n",
        "    return train_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fd55dee-4ea5-4247-8133-18efabba29fa",
      "metadata": {
        "id": "7fd55dee-4ea5-4247-8133-18efabba29fa"
      },
      "source": [
        "# Select Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a5a85a21-4612-42a1-b095-bba2b8bd5cc8",
      "metadata": {
        "id": "a5a85a21-4612-42a1-b095-bba2b8bd5cc8"
      },
      "outputs": [],
      "source": [
        "def select_device():\n",
        "    device = (\n",
        "        \"cuda\"\n",
        "        if torch.cuda.is_available()\n",
        "        else \"mps\"\n",
        "        if torch.backends.mps.is_available()\n",
        "        else \"cpu\"\n",
        "    )\n",
        "    return device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01780fa5-3e33-4d0c-bb6e-2bce7366b966",
      "metadata": {
        "id": "01780fa5-3e33-4d0c-bb6e-2bce7366b966"
      },
      "source": [
        "# Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0dc31549-5a22-4790-98db-be911a024512",
      "metadata": {
        "id": "0dc31549-5a22-4790-98db-be911a024512"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(17, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 35),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(35, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "def load_model(weights, device):\n",
        "    model = NeuralNetwork().to(device)\n",
        "    if os.path.exists(weights):\n",
        "         try:\n",
        "             model.load_state_dict(torch.load(weights, mmap=True, weights_only=True), assign=True)\n",
        "         except:\n",
        "             print(\"None weights were loaded\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd5a86e2-b9a4-45d9-8133-90777b8a0d66",
      "metadata": {
        "id": "fd5a86e2-b9a4-45d9-8133-90777b8a0d66"
      },
      "source": [
        "# Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "09107035-d401-4fbf-81bf-6a7ae6889d77",
      "metadata": {
        "id": "09107035-d401-4fbf-81bf-6a7ae6889d77"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn, device, best_accuracy, best_weights):\n",
        "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    accuracy = correct / size\n",
        "\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    if should_save_best_model(accuracy, best_accuracy):\n",
        "        best_accuracy = accuracy\n",
        "        best_weights = model.state_dict()\n",
        "\n",
        "    return best_accuracy, best_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g2rSXchYmv56",
      "metadata": {
        "id": "g2rSXchYmv56"
      },
      "source": [
        "## Save only the best weights (optional and not useful for all cases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "n-MdL8g8mwbS",
      "metadata": {
        "id": "n-MdL8g8mwbS"
      },
      "outputs": [],
      "source": [
        "def should_save_best_model(accuracy, best_accuracy):\n",
        "    return accuracy > best_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7b9dee4-2472-4618-93b6-7ede020c97c5",
      "metadata": {
        "id": "d7b9dee4-2472-4618-93b6-7ede020c97c5"
      },
      "source": [
        "# Personal data formulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "00cce26f-1a2f-425f-be03-38ac99fed52a",
      "metadata": {
        "id": "00cce26f-1a2f-425f-be03-38ac99fed52a"
      },
      "outputs": [],
      "source": [
        "def enter_data(model, device):\n",
        "    age = int(input(\"Enter your age: \"))\n",
        "\n",
        "    sex = int(input(\"Enter your sex (0 for female, 1 for male):\"))\n",
        "\n",
        "    chest_pain_type = int(input(\"Enter the type of chest pain (0-3): \"))\n",
        "\n",
        "    resting_blood_pressure = int(input(\"Enter your resting blood pressure (in mm Hg):\"))\n",
        "\n",
        "    cholesterol = int(input(\"Enter your cholesterol level (in mg/dl): \"))\n",
        "\n",
        "    fasting_blood_sugar = int(input(\"Enter your fasting blood sugar level (1 if > 120 mg/dl, 0 if not): \"))\n",
        "\n",
        "    rest_ecg = int(input(\"Enter the resting electrocardiographic results (0-2): \"))\n",
        "\n",
        "    max_heart_rate = int(input(\"Enter your maximum heart rate achieved: \"))\n",
        "\n",
        "    exercise_induced_angina = int(input(\"Did you have exercise-induced angina? (1 for yes, 0 for no): \"))\n",
        "\n",
        "    oldpeak = float(input(\"Enter the ST depression value induced by exercise (oldpeak): \"))\n",
        "\n",
        "    st_slope = int(input(\"Enter the slope of the peak exercise ST segment (0-2): \"))\n",
        "\n",
        "    major_vessels = int(input(\"Enter the number of major vessels colored by fluoroscopy (0-3): \"))\n",
        "\n",
        "    thalassemia = int(input(\"Enter the type of thalassemia (1 = normal, 2 = fixed defect, 3 = reversible defect): \"))\n",
        "\n",
        "    input_data = [age, sex, chest_pain_type, resting_blood_pressure, cholesterol, fasting_blood_sugar, rest_ecg,\n",
        "                  max_heart_rate, exercise_induced_angina, oldpeak, st_slope, major_vessels, thalassemia]\n",
        "\n",
        "    input_data = personal_data_split(input_data)\n",
        "    input_tensor = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        probabilities = torch.softmax(output, dim=1)\n",
        "        predicted_class = probabilities.argmax(1).item()\n",
        "\n",
        "    return predicted_class\n",
        "\n",
        "def personal_data_split(data):\n",
        "    rangos = [0, 30, 50, 70, 100]\n",
        "    edad_rangos = np.digitize([data[0]], rangos) - 1\n",
        "    sexo_one_hot = np.eye(2)[[data[1]]]\n",
        "    edad_one_hot = np.eye(len(rangos) - 1)[edad_rangos]\n",
        "\n",
        "    processed_data = np.hstack((data[2:], sexo_one_hot[0], edad_one_hot[0]))\n",
        "\n",
        "    return processed_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f3f0f9-5d9c-41f3-9ffb-3ba4258703c3",
      "metadata": {
        "id": "65f3f0f9-5d9c-41f3-9ffb-3ba4258703c3"
      },
      "source": [
        "# Main Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b2809379-a2c6-4b6e-a017-5876a179b423",
      "metadata": {
        "id": "b2809379-a2c6-4b6e-a017-5876a179b423"
      },
      "outputs": [],
      "source": [
        "def main(dataset, learning_rate, batch_size, epochs):\n",
        "    device = select_device()\n",
        "    model = load_model('model_weights.pth', device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    best_accuracy = 0.0\n",
        "    best_weights = None\n",
        "\n",
        "    train_on = input(\"Do you want to train? Yes(Any), No(enter): \")\n",
        "    if train_on:\n",
        "        full_dataset = import_dataset(dataset)\n",
        "        training_data, test_data = split_dataset(full_dataset)\n",
        "        train_dataloader, test_dataloader = create_dataloader(training_data, test_data, batch_size)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        next_train = True\n",
        "        while next_train:\n",
        "            for t in range(epochs):\n",
        "                print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "                train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
        "                best_accuracy, best_weights = test_loop(test_dataloader, model, loss_fn, device, best_accuracy, best_weights)\n",
        "\n",
        "            print(f\"Best accuracy: {(100 * best_accuracy):.1f}% with learning rate {learning_rate}\")\n",
        "            save_on = input(\"Do you want to save? Yes(Any), No(enter): \")\n",
        "            if save_on:\n",
        "              print(\"Done! Saving process...\")\n",
        "              torch.save(best_weights, 'model_weights.pth')\n",
        "\n",
        "            stop_train = input(\"Should we continue training? No(Any) Yes(Enter) -> \")\n",
        "            if stop_train:\n",
        "                next_train = False\n",
        "            else:\n",
        "                change_lr = input(\"Change the learning rate? Yes(Any) No(Enter) -> \")\n",
        "                if change_lr:\n",
        "                    try:\n",
        "                        learning_rate = float(input(\"New learning rate: \"))\n",
        "                    except:\n",
        "                        print(\"Ignoring new learning rate\")\n",
        "\n",
        "                change_epochs = input(f\"Change the number of epochs ({epochs})? Yes(Any) No(Enter) -> \")\n",
        "                if change_epochs:\n",
        "                    try:\n",
        "                        epochs = int(input(\"New number of epochs: \"))\n",
        "                    except:\n",
        "                        print(\"Ignoring new number of epochs\")\n",
        "    else:\n",
        "        print(f\"Predicted class: {enter_data(model, device)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e542b086-96ed-4afe-9c67-18cff3c33205",
      "metadata": {
        "id": "e542b086-96ed-4afe-9c67-18cff3c33205"
      },
      "source": [
        "# Call main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fe67d998-4d3f-4fa5-b29f-ecb98a03f4d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe67d998-4d3f-4fa5-b29f-ecb98a03f4d3",
        "outputId": "1853f6ec-f74f-466d-fdc8-14b365f1b8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.695862  [   32/  820]\n",
            "loss: 0.678714  [  352/  820]\n",
            "loss: 0.638947  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 78.5%, Avg loss: 0.583773 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.595600  [   32/  820]\n",
            "loss: 0.508486  [  352/  820]\n",
            "loss: 0.438125  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 78.5%, Avg loss: 0.451965 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.457614  [   32/  820]\n",
            "loss: 0.455769  [  352/  820]\n",
            "loss: 0.305455  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 80.5%, Avg loss: 0.404698 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.315443  [   32/  820]\n",
            "loss: 0.291230  [  352/  820]\n",
            "loss: 0.380989  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 79.5%, Avg loss: 0.369826 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.394827  [   32/  820]\n",
            "loss: 0.246502  [  352/  820]\n",
            "loss: 0.396212  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 0.362726 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.629273  [   32/  820]\n",
            "loss: 0.356374  [  352/  820]\n",
            "loss: 0.272874  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 82.0%, Avg loss: 0.352660 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.275603  [   32/  820]\n",
            "loss: 0.297853  [  352/  820]\n",
            "loss: 0.502807  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 81.0%, Avg loss: 0.342924 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.194918  [   32/  820]\n",
            "loss: 0.343914  [  352/  820]\n",
            "loss: 0.246397  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 83.4%, Avg loss: 0.333040 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.339857  [   32/  820]\n",
            "loss: 0.382878  [  352/  820]\n",
            "loss: 0.261325  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 83.4%, Avg loss: 0.328055 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.289441  [   32/  820]\n",
            "loss: 0.458907  [  352/  820]\n",
            "loss: 0.226636  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 0.326275 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.287829  [   32/  820]\n",
            "loss: 0.342778  [  352/  820]\n",
            "loss: 0.360446  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 0.319126 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.470200  [   32/  820]\n",
            "loss: 0.410960  [  352/  820]\n",
            "loss: 0.311324  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 0.312372 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.258140  [   32/  820]\n",
            "loss: 0.156975  [  352/  820]\n",
            "loss: 0.308255  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 85.9%, Avg loss: 0.319419 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.396108  [   32/  820]\n",
            "loss: 0.185030  [  352/  820]\n",
            "loss: 0.262867  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.309056 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.335952  [   32/  820]\n",
            "loss: 0.400298  [  352/  820]\n",
            "loss: 0.333897  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.322555 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.338942  [   32/  820]\n",
            "loss: 0.328927  [  352/  820]\n",
            "loss: 0.138290  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 85.9%, Avg loss: 0.297393 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.275536  [   32/  820]\n",
            "loss: 0.289113  [  352/  820]\n",
            "loss: 0.327355  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.299033 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.246463  [   32/  820]\n",
            "loss: 0.290628  [  352/  820]\n",
            "loss: 0.290901  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.287331 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.205747  [   32/  820]\n",
            "loss: 0.155124  [  352/  820]\n",
            "loss: 0.266093  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.281313 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.248107  [   32/  820]\n",
            "loss: 0.160513  [  352/  820]\n",
            "loss: 0.302901  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.274196 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.304677  [   32/  820]\n",
            "loss: 0.269359  [  352/  820]\n",
            "loss: 0.330611  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.269932 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.233177  [   32/  820]\n",
            "loss: 0.247455  [  352/  820]\n",
            "loss: 0.279278  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.266372 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.162801  [   32/  820]\n",
            "loss: 0.142835  [  352/  820]\n",
            "loss: 0.207545  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.258113 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.169283  [   32/  820]\n",
            "loss: 0.281604  [  352/  820]\n",
            "loss: 0.199915  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 88.8%, Avg loss: 0.257114 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.250247  [   32/  820]\n",
            "loss: 0.428089  [  352/  820]\n",
            "loss: 0.157153  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 0.251955 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.318373  [   32/  820]\n",
            "loss: 0.261837  [  352/  820]\n",
            "loss: 0.319146  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.244027 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.227625  [   32/  820]\n",
            "loss: 0.162013  [  352/  820]\n",
            "loss: 0.210378  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 88.3%, Avg loss: 0.238770 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.222633  [   32/  820]\n",
            "loss: 0.160891  [  352/  820]\n",
            "loss: 0.359174  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.236377 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.420783  [   32/  820]\n",
            "loss: 0.266010  [  352/  820]\n",
            "loss: 0.148099  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.7%, Avg loss: 0.227289 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.132379  [   32/  820]\n",
            "loss: 0.221437  [  352/  820]\n",
            "loss: 0.085084  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.218693 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.227395  [   32/  820]\n",
            "loss: 0.177568  [  352/  820]\n",
            "loss: 0.155769  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.217610 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.210298  [   32/  820]\n",
            "loss: 0.164925  [  352/  820]\n",
            "loss: 0.204034  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.215915 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.248217  [   32/  820]\n",
            "loss: 0.086544  [  352/  820]\n",
            "loss: 0.110575  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.205540 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.273773  [   32/  820]\n",
            "loss: 0.144273  [  352/  820]\n",
            "loss: 0.184418  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.208204 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.186783  [   32/  820]\n",
            "loss: 0.066705  [  352/  820]\n",
            "loss: 0.251977  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.197249 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.180460  [   32/  820]\n",
            "loss: 0.204552  [  352/  820]\n",
            "loss: 0.060248  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.191877 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.223762  [   32/  820]\n",
            "loss: 0.253169  [  352/  820]\n",
            "loss: 0.091138  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.187887 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.261504  [   32/  820]\n",
            "loss: 0.142466  [  352/  820]\n",
            "loss: 0.117844  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.189247 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.200023  [   32/  820]\n",
            "loss: 0.124102  [  352/  820]\n",
            "loss: 0.097021  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.177488 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.138824  [   32/  820]\n",
            "loss: 0.167324  [  352/  820]\n",
            "loss: 0.131674  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.173241 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.147149  [   32/  820]\n",
            "loss: 0.170769  [  352/  820]\n",
            "loss: 0.164726  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.164217 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.098349  [   32/  820]\n",
            "loss: 0.135793  [  352/  820]\n",
            "loss: 0.156402  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 89.8%, Avg loss: 0.184406 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.125238  [   32/  820]\n",
            "loss: 0.195536  [  352/  820]\n",
            "loss: 0.144849  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.166114 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.183054  [   32/  820]\n",
            "loss: 0.058647  [  352/  820]\n",
            "loss: 0.158074  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.164278 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.300023  [   32/  820]\n",
            "loss: 0.226851  [  352/  820]\n",
            "loss: 0.086436  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 90.2%, Avg loss: 0.166486 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.072107  [   32/  820]\n",
            "loss: 0.200774  [  352/  820]\n",
            "loss: 0.124258  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 91.7%, Avg loss: 0.155997 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.114695  [   32/  820]\n",
            "loss: 0.143987  [  352/  820]\n",
            "loss: 0.128334  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.151067 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.052289  [   32/  820]\n",
            "loss: 0.100476  [  352/  820]\n",
            "loss: 0.085423  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.147670 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.079939  [   32/  820]\n",
            "loss: 0.070198  [  352/  820]\n",
            "loss: 0.166473  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 92.7%, Avg loss: 0.151085 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.058409  [   32/  820]\n",
            "loss: 0.063482  [  352/  820]\n",
            "loss: 0.239384  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.149419 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.084735  [   32/  820]\n",
            "loss: 0.076037  [  352/  820]\n",
            "loss: 0.140989  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.143518 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.049662  [   32/  820]\n",
            "loss: 0.064994  [  352/  820]\n",
            "loss: 0.073526  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.148922 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.043515  [   32/  820]\n",
            "loss: 0.170499  [  352/  820]\n",
            "loss: 0.063712  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 93.2%, Avg loss: 0.140454 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.154187  [   32/  820]\n",
            "loss: 0.152026  [  352/  820]\n",
            "loss: 0.166978  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 95.1%, Avg loss: 0.128327 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.081503  [   32/  820]\n",
            "loss: 0.044467  [  352/  820]\n",
            "loss: 0.114755  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 93.2%, Avg loss: 0.127521 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.081230  [   32/  820]\n",
            "loss: 0.141848  [  352/  820]\n",
            "loss: 0.166520  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 92.2%, Avg loss: 0.153983 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.020685  [   32/  820]\n",
            "loss: 0.131014  [  352/  820]\n",
            "loss: 0.135048  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.122643 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.073415  [   32/  820]\n",
            "loss: 0.059864  [  352/  820]\n",
            "loss: 0.138730  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 94.1%, Avg loss: 0.125998 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.141542  [   32/  820]\n",
            "loss: 0.032221  [  352/  820]\n",
            "loss: 0.158151  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.120915 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.097479  [   32/  820]\n",
            "loss: 0.111798  [  352/  820]\n",
            "loss: 0.082048  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 95.1%, Avg loss: 0.118774 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.124914  [   32/  820]\n",
            "loss: 0.029122  [  352/  820]\n",
            "loss: 0.119407  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 95.1%, Avg loss: 0.121290 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.124514  [   32/  820]\n",
            "loss: 0.042265  [  352/  820]\n",
            "loss: 0.089882  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 95.1%, Avg loss: 0.116304 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.064798  [   32/  820]\n",
            "loss: 0.106008  [  352/  820]\n",
            "loss: 0.077714  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.109276 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.107661  [   32/  820]\n",
            "loss: 0.041031  [  352/  820]\n",
            "loss: 0.164443  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 95.1%, Avg loss: 0.110999 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.087954  [   32/  820]\n",
            "loss: 0.091993  [  352/  820]\n",
            "loss: 0.079994  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.106641 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.071365  [   32/  820]\n",
            "loss: 0.055839  [  352/  820]\n",
            "loss: 0.080455  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.112604 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.162818  [   32/  820]\n",
            "loss: 0.119741  [  352/  820]\n",
            "loss: 0.118724  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.110653 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.042427  [   32/  820]\n",
            "loss: 0.123401  [  352/  820]\n",
            "loss: 0.033800  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.104088 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.143539  [   32/  820]\n",
            "loss: 0.075101  [  352/  820]\n",
            "loss: 0.042975  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.103206 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.056816  [   32/  820]\n",
            "loss: 0.142295  [  352/  820]\n",
            "loss: 0.039689  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 94.1%, Avg loss: 0.113103 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.058914  [   32/  820]\n",
            "loss: 0.101419  [  352/  820]\n",
            "loss: 0.050670  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.103888 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.164876  [   32/  820]\n",
            "loss: 0.137946  [  352/  820]\n",
            "loss: 0.082020  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 97.6%, Avg loss: 0.095636 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.036166  [   32/  820]\n",
            "loss: 0.080950  [  352/  820]\n",
            "loss: 0.142986  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.099187 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.139749  [   32/  820]\n",
            "loss: 0.075357  [  352/  820]\n",
            "loss: 0.022456  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.091217 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.033015  [   32/  820]\n",
            "loss: 0.041637  [  352/  820]\n",
            "loss: 0.087146  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.102843 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.048517  [   32/  820]\n",
            "loss: 0.079688  [  352/  820]\n",
            "loss: 0.067262  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 97.6%, Avg loss: 0.088935 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.028502  [   32/  820]\n",
            "loss: 0.046352  [  352/  820]\n",
            "loss: 0.147666  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 94.1%, Avg loss: 0.100682 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.071775  [   32/  820]\n",
            "loss: 0.044913  [  352/  820]\n",
            "loss: 0.028375  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.085697 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.029959  [   32/  820]\n",
            "loss: 0.095630  [  352/  820]\n",
            "loss: 0.112746  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.090487 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.043015  [   32/  820]\n",
            "loss: 0.066843  [  352/  820]\n",
            "loss: 0.037689  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.090007 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.056337  [   32/  820]\n",
            "loss: 0.091975  [  352/  820]\n",
            "loss: 0.033902  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.089504 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.103835  [   32/  820]\n",
            "loss: 0.026120  [  352/  820]\n",
            "loss: 0.074541  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.091856 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.118920  [   32/  820]\n",
            "loss: 0.037210  [  352/  820]\n",
            "loss: 0.054226  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.090752 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.110902  [   32/  820]\n",
            "loss: 0.058875  [  352/  820]\n",
            "loss: 0.032679  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.083082 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.011588  [   32/  820]\n",
            "loss: 0.063255  [  352/  820]\n",
            "loss: 0.090039  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.079418 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.042472  [   32/  820]\n",
            "loss: 0.053914  [  352/  820]\n",
            "loss: 0.075984  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 97.6%, Avg loss: 0.081514 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.081589  [   32/  820]\n",
            "loss: 0.016924  [  352/  820]\n",
            "loss: 0.052387  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.073942 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.074920  [   32/  820]\n",
            "loss: 0.130585  [  352/  820]\n",
            "loss: 0.050752  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.107168 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.048092  [   32/  820]\n",
            "loss: 0.044765  [  352/  820]\n",
            "loss: 0.032126  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 95.6%, Avg loss: 0.090297 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.039610  [   32/  820]\n",
            "loss: 0.094223  [  352/  820]\n",
            "loss: 0.042478  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.077095 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.025651  [   32/  820]\n",
            "loss: 0.058428  [  352/  820]\n",
            "loss: 0.084038  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.092850 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.030658  [   32/  820]\n",
            "loss: 0.028677  [  352/  820]\n",
            "loss: 0.093241  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.073146 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.014830  [   32/  820]\n",
            "loss: 0.045519  [  352/  820]\n",
            "loss: 0.039761  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.076207 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.030506  [   32/  820]\n",
            "loss: 0.076036  [  352/  820]\n",
            "loss: 0.070509  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.083608 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.098326  [   32/  820]\n",
            "loss: 0.028969  [  352/  820]\n",
            "loss: 0.106459  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 0.068084 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.006239  [   32/  820]\n",
            "loss: 0.052908  [  352/  820]\n",
            "loss: 0.078839  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 0.066259 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.035713  [   32/  820]\n",
            "loss: 0.007914  [  352/  820]\n",
            "loss: 0.068367  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 0.064617 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.019186  [   32/  820]\n",
            "loss: 0.017380  [  352/  820]\n",
            "loss: 0.225952  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 94.6%, Avg loss: 0.093026 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.035195  [   32/  820]\n",
            "loss: 0.044854  [  352/  820]\n",
            "loss: 0.008212  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.063147 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.018875  [   32/  820]\n",
            "loss: 0.058798  [  352/  820]\n",
            "loss: 0.010072  [  672/  820]\n",
            "Test Error: \n",
            " Accuracy: 97.1%, Avg loss: 0.065858 \n",
            "\n",
            "Best accuracy: 98.0% with learning rate 0.001\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    dataset = 'dataset/heart.csv'\n",
        "    learning_rate = 1e-3\n",
        "    batch_size = 32\n",
        "    epochs = 100\n",
        "    main(dataset,learning_rate,batch_size,epochs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
